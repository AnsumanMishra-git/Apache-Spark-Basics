## Problem 3  
We have a file windowdata.csv and the field names are country, weeknum,numinvoices, totalquantity, invoicevalue  
Step 1: create spark session  
Step 2: set the logging level to error  
Step 3: Using the standard dataframe reader API load the file and create a dataframe.  
Note: The schema should be provided using StructType (do not use infer schema)  
Step 4: Use the standard dataframe writer api to save it in parquet format. While saving make sure data is stored where we should have a folder for each country, weeknum (combination)
